# FlexWorld å¢é‡å¼RGBDè¡¥å…¨ - å½“å‰å®ç°åˆ†æ

## æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†åˆ†æå½“å‰FlexWorld + FLUX.1-dev-Controlnet-Inpaintingçš„å¢é‡å¼3Dåœºæ™¯è¡¥å…¨å®ç°ï¼ŒåŒ…æ‹¬å·¥ä½œåŸç†ã€æŠ€æœ¯ç»†èŠ‚ã€é—®é¢˜åˆ†æå’Œæ”¹è¿›æ–¹å‘ã€‚

## æœ€æ–°çŠ¶æ€æ›´æ–° (2025-08-14)

### âœ… å·²è§£å†³çš„é—®é¢˜
1. **æ–‡ä»¶å¤§å°ç¼©å°åŸå› **: ç¡®è®¤æ˜¯æ³•å‘é‡è¢«ä¸¢å¼ƒï¼ˆä¸å½±å“æ¸²æŸ“ï¼‰
2. **ç‚¹äº‘ç¡®å®åœ¨å¢é•¿**: 1,843,200 â†’ 1,865,913ç‚¹ (+22,713ç‚¹, +1.23%)
3. **Maskå¤„ç†å¯¹é½**: é˜ˆå€¼æ”¹ä¸ºâ‰¤6ï¼Œæ·»åŠ è†¨èƒ€å¤„ç†
4. **ç›¸æœºè½¨è¿¹æ­£å¸¸**: 72å¸§è½¨è¿¹ï¼Œè§†è§’æ­£ç¡®å˜åŒ–

### ğŸ” æœ€æ–°å‘ç°çš„æ ¸å¿ƒé—®é¢˜
1. **æ·±åº¦ä¼°è®¡Scaleé”™è¯¯**: æ–°å¢ç‚¹çš„scaleåªæœ‰åŸå§‹ç‚¹äº‘çš„7%ï¼ˆ3.2 vs 45.7ï¼‰
2. **æ·±åº¦èŒƒå›´ä¸åŒ¹é…**: cv2.inpaintç®€å•æ’å€¼ä¸ç†è§£3Dåœºæ™¯çœŸå®æ·±åº¦
3. **ç¼ºå°‘æ·±åº¦çº¦æŸ**: ä¼°è®¡æ·±åº¦æ²¡æœ‰åŸºäºæœ‰æ•ˆæ·±åº¦çš„ç»Ÿè®¡çº¦æŸ

---

## 1. æ•´ä½“æ¶æ„

### 1.1 æ ¸å¿ƒæµç¨‹
```
åˆå§‹ç‚¹äº‘ â†’ é¢„æ„å»ºè½¨è¿¹(72å¸§) â†’ é€è§†è§’å¤„ç† â†’ ç´¯ç§¯æ›´æ–°ç‚¹äº‘
         â†“
    å•è§†è§’æµç¨‹ï¼šæ¸²æŸ“ â†’ æ£€æµ‹ç¼ºå¤± â†’ FLUXè¡¥å…¨ â†’ æ·±åº¦ä¼°è®¡ â†’ 3Dé‡å»º â†’ ç‚¹äº‘æ›´æ–°
```

### 1.2 ä¸»è¦æ–‡ä»¶
- `incremental_pipeline.py`: ä¸»è¦å¢é‡å¼pipeline (âœ… ç›¸æœºç§»åŠ¨å·²ä¿®å¤)
- `flux_inpaint_simple.py`: åŸºç¡€FLUX inpaintingåŠŸèƒ½
- `ljj.py`: FlexWorldç‚¹äº‘æ¸²æŸ“å’Œè§†é¢‘ç”Ÿæˆpipeline (å‚è€ƒå®ç°)
- `street_pointcloud.ply`: æµ‹è¯•ç”¨è¡—æ™¯ç‚¹äº‘ (89.6MB)

---

## 2. FLUX Inpainting è¯¦ç»†æŠ€æœ¯åˆ†æ

### 2.1 æ¨¡å‹åŠ è½½æœºåˆ¶

#### æœ¬åœ°æ¨¡å‹ç»„ä»¶
- **FLUX Transformer**: `/mnt/pretrained/models--black-forest-labs--FLUX.1-dev/.../transformer/` (~23GB)
- **ControlNet**: `/mnt2/FLUX.1-dev-Controlnet-Inpainting-Alpha/` (~5GB)
- **å…¶ä»–ç»„ä»¶**: VAE, Text Encoders, Tokenizers (æœ¬åœ°å®Œæ•´)

#### åŠ è½½ç­–ç•¥
```python
# éªŒè¯å¯è¡Œçš„åŠ è½½æ–¹æ³•
controlnet = FluxControlNetModel.from_pretrained(
    "/mnt2/FLUX.1-dev-Controlnet-Inpainting-Alpha",
    torch_dtype=torch.bfloat16,
    local_files_only=True  # å¼ºåˆ¶æœ¬åœ°åŠ è½½
)

transformer = FluxTransformer2DModel.from_pretrained(
    "/mnt/pretrained/.../FLUX.1-dev/snapshots/...",
    subfolder='transformer',
    torch_dtype=torch.bfloat16,
    local_files_only=True
)

pipeline = FluxControlNetInpaintingPipeline.from_pretrained(
    "/mnt/pretrained/.../FLUX.1-dev/snapshots/...",
    controlnet=controlnet,
    transformer=transformer,
    torch_dtype=torch.bfloat16,
    local_files_only=True
)
```

### 2.2 Maskå¤„ç†æœºåˆ¶

#### FlexWorld Alpha Mask è¯­ä¹‰
- **å€¼åŸŸ**: [0, 255] (uint8)
- **è¯­ä¹‰**:
  - `0`: å®Œå…¨é€æ˜ â†’ è¯¥åƒç´ å®Œå…¨æ²¡æœ‰ç‚¹äº‘è¦†ç›– â†’ **éœ€è¦inpaint**
  - `1-254`: åŠé€æ˜ â†’ è¯¥åƒç´ æœ‰éƒ¨åˆ†ç‚¹äº‘è¦†ç›– â†’ **ä¸éœ€è¦inpaint**
  - `255`: å®Œå…¨ä¸é€æ˜ â†’ è¯¥åƒç´ æœ‰å®Œæ•´ç‚¹äº‘è¦†ç›– â†’ **ä¸éœ€è¦inpaint**

#### FLUX Mask è½¬æ¢
```python
# FlexWorld â†’ FLUX æ ¼å¼è½¬æ¢
flexworld_mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)  # [0,255]
flux_mask = np.zeros_like(flexworld_mask)
flux_mask[flexworld_mask == 0] = 255  # ç™½è‰²=inpaint, é»‘è‰²=keep

# ç»Ÿè®¡ç»“æœ (ä»¥frame_000ä¸ºä¾‹)
total_pixels = 262,144  # 512Ã—512
need_inpaint = 620      # å€¼=0çš„åƒç´ 
has_geometry = 261,524  # å€¼>0çš„åƒç´ 
inpaint_ratio = 0.24%   # æå°‘é‡éœ€è¦è¡¥å…¨
```

### 2.3 FLUXæ¨ç†å‚æ•°

#### æ ¸å¿ƒå‚æ•°é…ç½®
```python
result = flux_pipeline(
    prompt="complete urban street scene with buildings, road surface, and infrastructure details",
    height=768, width=768,              # FLUXæœ€ä¼˜åˆ†è¾¨ç‡
    control_image=image_pil,            # æ§åˆ¶è¾“å…¥å›¾åƒ
    control_mask=mask_pil,              # æ§åˆ¶mask
    num_inference_steps=28,             # å®˜æ–¹æ¨èæ­¥æ•°
    generator=torch.Generator().manual_seed(42),  # å›ºå®šéšæœºç§å­
    controlnet_conditioning_scale=0.9,   # ControlNetçº¦æŸå¼ºåº¦
    guidance_scale=3.5,                 # CFGå¼•å¯¼å¼ºåº¦  
    negative_prompt="blurry, low quality, distorted",
    true_guidance_scale=1.0             # FLUX-devç‰¹æœ‰å‚æ•°
)
```

#### å‚æ•°æ„ä¹‰åˆ†æ
- **`controlnet_conditioning_scale=0.9`**: 
  - å¼ºçº¦æŸ (0.9 æ¥è¿‘1.0)
  - ä¿æŒéinpaintåŒºåŸŸå‡ ä¹å®Œå…¨ä¸å˜
  - å¯¹inpaintåŒºåŸŸè¿›è¡Œç²¾ç¡®æ§åˆ¶
  
- **`guidance_scale=3.5`**:
  - é€‚ä¸­çš„æ–‡æœ¬å¼•å¯¼å¼ºåº¦
  - å¹³è¡¡ç”Ÿæˆè´¨é‡å’Œå¤šæ ·æ€§
  - FLUXæ¨èèŒƒå›´ [1.0, 5.0]
  
- **`true_guidance_scale=1.0`**:
  - FLUX.1-devç‰ˆæœ¬ä¸“ç”¨å‚æ•°
  - ä¸ä¼ ç»ŸCFGä¸åŒçš„å¼•å¯¼æœºåˆ¶

### 2.4 å°ºå¯¸è½¬æ¢ç­–ç•¥

#### è½¬æ¢é“¾è·¯
```python
FlexWorld (512Ã—512) â†’ FLUXå¤„ç† (768Ã—768) â†’ FlexWorld (512Ã—512)
```

#### è½¬æ¢ç»†èŠ‚
```python
# 1. FlexWorld â†’ FLUX
image_pil = Image.fromarray(rgb_image).resize((768, 768), Image.LANCZOS)
mask_pil = Image.fromarray(flux_mask).resize((768, 768), Image.NEAREST)  # maskç”¨æœ€è¿‘é‚»

# 2. FLUXæ¨ç† (768Ã—768)
result = flux_pipeline(...)  # åœ¨768Ã—768åˆ†è¾¨ç‡ä¸‹å¤„ç†

# 3. FLUX â†’ FlexWorld
final_result = result.resize((512, 512), Image.LANCZOS)
```

#### å°ºå¯¸é€‰æ‹©ç†ç”±
- **768Ã—768**: FLUX.1-devçš„è®­ç»ƒæœ€ä¼˜åˆ†è¾¨ç‡
- **512Ã—512**: FlexWorldé¡¹ç›®çš„æ ‡å‡†å¸§å°ºå¯¸  
- **åŒé‡resize**: è™½æœ‰è´¨é‡æŸå¤±ï¼Œä½†ä¿è¯å…¼å®¹æ€§

---

## 3. Promptå·¥ç¨‹åˆ†æ

### 3.1 å½“å‰Promptç­–ç•¥

#### å›ºå®šPrompt
```python
prompt = "complete urban street scene with buildings, road surface, and infrastructure details"
```

#### Promptæ„æˆåˆ†æ
- **"complete"**: æŒ‡ç¤ºè¡¥å…¨ä»»åŠ¡
- **"urban street scene"**: åœºæ™¯ç±»å‹å®šä¹‰
- **"buildings"**: å…·ä½“å…ƒç´ å¼•å¯¼
- **"road surface"**: åœ°é¢ç»†èŠ‚è¡¥å…¨
- **"infrastructure details"**: åŸå¸‚è®¾æ–½å…ƒç´ 

### 3.2 Promptå±€é™æ€§

#### é—®é¢˜
1. **é™æ€å›ºå®š**: ä¸æ ¹æ®å®é™…å›¾åƒå†…å®¹è°ƒæ•´
2. **è¿‡äºé€šç”¨**: ç¼ºä¹é’ˆå¯¹æ€§æè¿°
3. **ç¼ºä¹ä¸Šä¸‹æ–‡**: ä¸è€ƒè™‘å·²æœ‰åƒç´ çš„å…·ä½“å†…å®¹
4. **é£æ ¼ä¸ä¸€è‡´**: å¯èƒ½ä¸åŸå›¾é£æ ¼å†²çª

#### æ”¹è¿›æ–¹å‘
```python
def generate_adaptive_prompt(rgb_image, alpha_mask, missing_region):
    # åˆ†ææœ‰æ•ˆåŒºåŸŸå†…å®¹
    valid_pixels = rgb_image[alpha_mask > 0]
    
    # é¢œè‰²åˆ†æ
    dominant_colors = analyze_color_palette(valid_pixels)
    
    # åŒºåŸŸä½ç½®åˆ†æ
    missing_location = analyze_missing_region_position(missing_region)
    
    # å‘¨è¾¹å†…å®¹åˆ†æ  
    nearby_features = analyze_nearby_pixels(rgb_image, alpha_mask, missing_region)
    
    # åŠ¨æ€ç”Ÿæˆprompt
    if missing_location == "ground":
        prompt = f"street pavement and road surface, {dominant_colors} tones"
    elif missing_location == "building":
        prompt = f"architectural details, {nearby_features} building style"
    else:
        prompt = f"urban scene continuation, matching {dominant_colors} environment"
    
    return prompt
```

---

## 4. å¢é‡å¼ç‚¹äº‘æ›´æ–°æœºåˆ¶

### 4.1 å¤„ç†æµç¨‹

#### å•è§†è§’å¤„ç†å¾ªç¯
```python
for cam in camera_trajectory:
    # Step 1: æ¸²æŸ“å½“å‰è§†è§’
    rgb_render = pcd.render(cam)                    # [3,H,W] â†’ [H,W,3]
    alpha_render = pcd.render(cam, mask=True)       # [H,W]
    
    # Step 2: åˆ†æç¼ºå¤±åŒºåŸŸ
    missing_pixels = np.sum(alpha_render == 0)
    if missing_pixels == 0:
        continue  # è·³è¿‡å®Œæ•´è§†è§’
    
    # Step 3: FLUX RGBè¡¥å…¨
    completed_rgb = flux_inpaint(rgb_render, alpha_render, prompt)
    
    # Step 4: æ·±åº¦ä¼°è®¡ (é—®é¢˜ç¯èŠ‚)
    estimated_depth = estimate_depth_simple(completed_rgb)
    
    # Step 5: 3Dé‡å»º
    points_3d = depth2pcd_world(estimated_depth, cam)
    
    # Step 6: ç‚¹äº‘æ›´æ–°
    missing_mask = alpha_render == 0
    new_points_6d = np.concatenate([
        points_3d[missing_mask],           # XYZ
        completed_rgb[missing_mask]/255    # RGB
    ], axis=1)
    
    pcd.add_pts(new_points_6d)  # ç´¯ç§¯æ·»åŠ åˆ°ç‚¹äº‘
```

### 4.2 åæ ‡ç³»è½¬æ¢

#### depth2pcd_world å‡½æ•°åˆ†æ
```python
def depth2pcd_world(depth_map, cam: Mcam):
    # åŠŸèƒ½ï¼šå°†æ·±åº¦å›¾è½¬æ¢ä¸ºä¸–ç•Œåæ ‡ç³»3Dç‚¹
    # è¾“å…¥ï¼šdepth_map [H,W], cam (åŒ…å«å†…å‚ã€å¤–å‚)
    # è¾“å‡ºï¼špoints_3d [H,W,3] ä¸–ç•Œåæ ‡
    
    # åƒç´ åæ ‡ â†’ ç›¸æœºåæ ‡ â†’ ä¸–ç•Œåæ ‡
    # æ¶‰åŠç›¸æœºå†…å‚çŸ©é˜µå’Œå¤–å‚å˜æ¢
```

#### æ½œåœ¨é—®é¢˜
1. **åæ ‡ç³»ä¸ä¸€è‡´**: FlexWorldå’Œç›¸æœºåæ ‡ç³»å¯èƒ½æœ‰å·®å¼‚
2. **æ·±åº¦å•ä½**: ä¼°è®¡çš„æ·±åº¦å•ä½ä¸å®é™…ç‚¹äº‘ä¸åŒ¹é…
3. **ç›¸æœºå‚æ•°**: å†…å‚å¤–å‚æ˜¯å¦å‡†ç¡®

---

## 5. æ·±åº¦ä¼°è®¡æ¨¡å—

### 5.1 å½“å‰å®ç° (ç®€å•æ¢¯åº¦æ–¹æ³•)

```python
def estimate_depth_simple(rgb_image):
    gray = cv2.cvtColor(rgb_image, cv2.COLOR_RGB2GRAY)
    
    # è®¡ç®—æ¢¯åº¦
    grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
    grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
    gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
    
    # æ¢¯åº¦ â†’ æ·±åº¦æ˜ å°„
    gradient_norm = gradient_magnitude / (np.max(gradient_magnitude) + 1e-8)
    depth_map = 1.0 - gradient_norm  # é«˜æ¢¯åº¦=è¾¹ç¼˜=è¿‘ï¼Œä½æ¢¯åº¦=å¹³å¦=è¿œ
    
    # ç¼©æ”¾åˆ°åˆç†èŒƒå›´
    depth_map = 0.5 + depth_map * 4.5  # [0.5, 5.0]
    
    return depth_map
```

### 5.2 æ·±åº¦ä¼°è®¡é—®é¢˜åˆ†æ

#### æ ¹æœ¬é—®é¢˜
1. **è¿‡äºç®€åŒ–**: æ¢¯åº¦â‰ æ·±åº¦ï¼Œç‰©ç†æ„ä¹‰ä¸æ­£ç¡®
2. **ç¼ºä¹è¯­ä¹‰**: ä¸è€ƒè™‘ç‰©ä½“ç±»åˆ«å’Œç©ºé—´å…³ç³»
3. **å°ºåº¦é”™è¯¯**: æ·±åº¦èŒƒå›´[0.5, 5.0]å¯èƒ½ä¸å®é™…åœºæ™¯ä¸ç¬¦
4. **ç¼ºä¹ä¸€è‡´æ€§**: ä¸å‘¨è¾¹å·²æœ‰æ·±åº¦æ²¡æœ‰å¯¹é½

#### æ”¹è¿›æ–¹æ¡ˆ

##### æ–¹æ¡ˆ1: åŸºäºå­¦ä¹ çš„æ·±åº¦ä¼°è®¡
```python
def estimate_depth_with_model(rgb_image):
    # ä½¿ç”¨MiDaS, DPT, æˆ–å…¶ä»–é¢„è®­ç»ƒæ·±åº¦ä¼°è®¡æ¨¡å‹
    import torch
    from transformers import pipeline
    
    depth_estimator = pipeline('depth-estimation', model='Intel/dpt-large')
    depth_result = depth_estimator(rgb_image)
    return depth_result['depth']
```

##### æ–¹æ¡ˆ2: åŸºäºå‘¨è¾¹æ·±åº¦æ’å€¼
```python
def estimate_depth_by_interpolation(original_depth, alpha_mask, completed_rgb):
    # åŸºäºå‘¨è¾¹æœ‰æ•ˆæ·±åº¦è¿›è¡Œæ’å€¼
    valid_depth = original_depth[alpha_mask > 0]
    missing_region = alpha_mask == 0
    
    # ä½¿ç”¨opencvçš„inpaintingå¯¹æ·±åº¦è¿›è¡Œè¡¥å…¨
    depth_inpainted = cv2.inpaint(
        original_depth.astype(np.float32),
        missing_region.astype(np.uint8),
        inpaintRadius=5,
        flags=cv2.INPAINT_TELEA
    )
    
    return depth_inpainted
```

##### æ–¹æ¡ˆ3: ä½¿ç”¨FlexWorldçš„æ·±åº¦å¯¹é½
```python
def estimate_depth_with_refinement(original_depth, estimated_depth, missing_mask):
    # ä½¿ç”¨FlexWorldçš„refine_depth2è¿›è¡Œå¯¹é½
    from ops.utils.depth import refine_depth2
    
    refined_depth = refine_depth2(
        render_dpt=original_depth,      # åŸå§‹æ¸²æŸ“æ·±åº¦
        ipaint_dpt=estimated_depth,     # ä¼°è®¡æ·±åº¦
        ipaint_msk=missing_mask,        # ç¼ºå¤±åŒºåŸŸmask
        iters=100,                      # è¿­ä»£æ¬¡æ•°
        blur_size=15,                   # å¹³æ»‘æ ¸å¤§å°
        scaled=True                     # æ˜¯å¦ç¼©æ”¾å¯¹é½
    )
    
    return refined_depth
```

---

## 6. æ€§èƒ½å’Œè´¨é‡åˆ†æ

### 6.1 æœ€æ–°æµ‹è¯•ç»“æœ (2025-08-14)

#### ç‚¹äº‘æ•°æ®å¯¹æ¯”
```
âœ… ç‚¹äº‘ç¡®å®åœ¨å¢é•¿:
åŸå§‹ç‚¹äº‘: 1,843,200ç‚¹ (89.65MBå¸¦æ³•å‘é‡ / 47.46MBä¸å¸¦æ³•å‘é‡)
å¤„ç†åç‚¹äº‘: 1,865,913ç‚¹ (48.05MBä¸å¸¦æ³•å‘é‡)
ç‚¹æ•°å¢é•¿: +22,713ç‚¹ (+1.23%)

æ–‡ä»¶å˜å°åŸå› : æ³•å‘é‡è¢«PcdMgrä¸¢å¼ƒï¼ˆ89MBâ†’48MBï¼‰ï¼Œä¸å½±å“æ¸²æŸ“
```

#### Scaleé—®é¢˜åˆ†æ
```
ğŸ” æ–°å¢ç‚¹Scaleä¸¥é‡åå°:
åŸå§‹ç‚¹äº‘èŒƒå›´: X[-45.7, 39.4], Y[-21.5, 24.8], Z[-25.4, 0.5]
åŸå§‹ç‚¹äº‘æœ€å¤§scale: 45.747

æ–°å¢ç‚¹èŒƒå›´: X[-1.4, 1.7], Y[-0.6, 1.5], Z[-3.2, 1.6]  
æ–°å¢ç‚¹æœ€å¤§scale: 3.213
Scaleæ¯”ä¾‹: ä»…ä¸ºåŸå§‹çš„7%ï¼

æ ¹æœ¬åŸå› : cv2.inpaintæ·±åº¦ä¼°è®¡ä¸å‡†ç¡®
```

#### è´¨é‡è¯„ä¼°æ›´æ–°
- **ç‚¹äº‘å¢é•¿**: âœ… æ­£å¸¸ - å¢é•¿1.23%
- **æ–‡ä»¶å¤§å°**: âœ… æ­£å¸¸ - æ³•å‘é‡ä¸¢å¼ƒå¯¼è‡´
- **FLUXè¡¥å…¨**: âœ… å¥½ - é¢œè‰²çº¹ç†è‡ªç„¶
- **æ·±åº¦ä¼°è®¡**: âŒ å·® - Scaleåªæœ‰7%ï¼Œä¸¥é‡åå°
- **æ¸²æŸ“æ•ˆæœ**: âŒ å·® - æ–°å¢ç‚¹å¤ªå°å‡ ä¹çœ‹ä¸è§

### 6.2 é—®é¢˜æ€»ç»“

#### æ ¸å¿ƒé—®é¢˜ï¼šæ·±åº¦ä¼°è®¡Scaleé”™è¯¯
1. **cv2.inpaintå±€é™**ï¼šä»…åšå›¾åƒæ’å€¼ï¼Œä¸ç†è§£3Dåœºæ™¯
2. **æ·±åº¦èŒƒå›´å¤±æ•ˆ**ï¼šä¼°è®¡æ·±åº¦[0.3, 1.0] vs å®é™…éœ€æ±‚
3. **ç¼ºä¹ç»Ÿè®¡çº¦æŸ**ï¼šæœªåŸºäºæœ‰æ•ˆæ·±åº¦çš„åˆ†å¸ƒè¿›è¡Œçº¦æŸ
4. **åæŠ•å½±Scaleé”™è¯¯**ï¼šå¯¼è‡´3Dç‚¹åœ¨é”™è¯¯çš„ç©ºé—´ä½ç½®

#### å·²ä¿®å¤çš„é—®é¢˜
1. **æ³•å‘é‡ä¸¢å¤±**ï¼šâœ… ç¡®è®¤ä¸å½±å“æ¸²æŸ“
2. **ç›¸æœºè½¨è¿¹**ï¼šâœ… 72å¸§é¢„æ„å»ºè½¨è¿¹æ­£å¸¸
3. **Maskå¤„ç†**ï¼šâœ… å·²å¯¹é½flux_inpaint_simple.py

---

## 7. æ”¹è¿›è·¯çº¿å›¾

### 7.1 ç«‹å³ä¼˜å…ˆçº§ (P0) - ä¿®å¤æ·±åº¦ä¼°è®¡
1. **æ”¹è¿›æ·±åº¦ä¼°è®¡æ–¹æ³•** ğŸ¯
   - å®ç°scale_awareæ·±åº¦ä¼°è®¡ï¼šåŸºäºæœ‰æ•ˆæ·±åº¦ç»Ÿè®¡çº¦æŸ
   - æ·»åŠ æ·±åº¦èŒƒå›´æ£€æŸ¥ï¼šçº¦æŸåˆ°[mean-std, mean+std]
   - ä½¿ç”¨nearest_neighboræˆ–plane_fittingæ–¹æ³•
   
2. **æ·»åŠ Scaleè‡ªåŠ¨ä¿®æ­£** ğŸ”§
   - æ£€æµ‹æ–°å¢ç‚¹scaleå¼‚å¸¸ï¼ˆ<20%æˆ–>500%ï¼‰
   - è‡ªåŠ¨è®¡ç®—å¹¶åº”ç”¨ç¼©æ”¾å› å­
   - ä¿å®ˆä¿®æ­£ç­–ç•¥ï¼ˆÃ—0.5æˆ–Ã—2ï¼‰

### 7.2 ä¸­æœŸä¼˜åŒ– (P1) - ç³»ç»Ÿå®Œå–„
1. **é›†æˆä¿®å¤æ–¹æ¡ˆ**
   - å°†fix_depth_estimation.pyé›†æˆåˆ°pipeline
   - æ·»åŠ å®æ—¶scaleç›‘æ§å’Œä¿®æ­£
   
2. **è´¨é‡è¯„ä¼°æŒ‡æ ‡**
   - æ–°å¢ç‚¹ç©ºé—´åˆ†å¸ƒæ£€æŸ¥
   - æ·±åº¦ä¸€è‡´æ€§éªŒè¯

### 7.3 é•¿æœŸæ”¹è¿› (P2) - åŠŸèƒ½æ‰©å±•
1. **æ›´å¼ºæ·±åº¦ä¼°è®¡**
   - é›†æˆMiDaS/DPTé¢„è®­ç»ƒæ¨¡å‹
   - å¤šè§†è§’æ·±åº¦ä¸€è‡´æ€§çº¦æŸ
   
2. **æ¸²æŸ“è´¨é‡ä¼˜åŒ–**
   - ç‚¹äº‘åå¤„ç†å’Œå»å™ª
   - è‡ªé€‚åº”Promptç”Ÿæˆ

---

## 8. å®éªŒå»ºè®®

### 8.1 æ·±åº¦ä¼°è®¡å¯¹æ¯”å®éªŒ
- **Baseline**: å½“å‰æ¢¯åº¦æ–¹æ³•
- **Method 1**: MiDaSæ·±åº¦ä¼°è®¡
- **Method 2**: OpenCVæ·±åº¦æ’å€¼  
- **Method 3**: FlexWorldæ·±åº¦å¯¹é½
- **è¯„ä¼°æŒ‡æ ‡**: 3Dç‚¹äº‘è´¨é‡ã€è§†è§‰ä¸€è‡´æ€§

### 8.2 Promptä¼˜åŒ–å®éªŒ
- **Baseline**: å›ºå®šé€šç”¨prompt
- **Method 1**: åŸºäºé¢œè‰²åˆ†æçš„åŠ¨æ€prompt
- **Method 2**: åŸºäºåŒºåŸŸä½ç½®çš„æ¡ä»¶prompt
- **è¯„ä¼°æŒ‡æ ‡**: FLUXè¡¥å…¨è´¨é‡ã€é£æ ¼ä¸€è‡´æ€§

### 8.3 å‚æ•°è°ƒä¼˜å®éªŒ
- **å˜é‡**: controlnet_conditioning_scale [0.7, 0.8, 0.9, 1.0]
- **å˜é‡**: guidance_scale [2.0, 3.5, 5.0]
- **è¯„ä¼°æŒ‡æ ‡**: è¡¥å…¨è´¨é‡ã€å¤„ç†æ—¶é—´

---

## 9. å…³é”®ä»£ç ç‰‡æ®µ

### 9.1 ä¿®å¤ç‰ˆæ·±åº¦ä¼°è®¡
```python
def estimate_depth_improved(completed_rgb, original_depth, alpha_mask):
    """æ”¹è¿›çš„æ·±åº¦ä¼°è®¡æ–¹æ³•"""
    missing_mask = alpha_mask == 0
    
    if np.sum(missing_mask) == 0:
        return original_depth
    
    # æ–¹æ³•1: ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹
    try:
        import torch
        from transformers import pipeline
        depth_estimator = pipeline('depth-estimation', model='Intel/dpt-large')
        estimated_depth = depth_estimator(completed_rgb)['depth']
        estimated_depth = np.array(estimated_depth)
    except:
        # æ–¹æ³•2: åŸºäºæ’å€¼çš„fallback
        estimated_depth = cv2.inpaint(
            original_depth.astype(np.float32),
            missing_mask.astype(np.uint8) * 255,
            inpaintRadius=10,
            flags=cv2.INPAINT_TELEA
        )
    
    # æ–¹æ³•3: ä½¿ç”¨FlexWorldå¯¹é½
    try:
        from ops.utils.depth import refine_depth2
        refined_depth = refine_depth2(
            render_dpt=original_depth,
            ipaint_dpt=estimated_depth,
            ipaint_msk=missing_mask,
            iters=50,
            blur_size=15,
            scaled=True
        )
        return refined_depth
    except:
        return estimated_depth
```

### 9.2 è‡ªé€‚åº”Promptç”Ÿæˆ
```python
def generate_adaptive_prompt(rgb_image, alpha_mask):
    """åŸºäºå›¾åƒå†…å®¹ç”Ÿæˆè‡ªé€‚åº”prompt"""
    valid_pixels = rgb_image[alpha_mask > 0]
    
    # åˆ†æä¸»å¯¼é¢œè‰²
    from sklearn.cluster import KMeans
    colors_flat = valid_pixels.reshape(-1, 3)
    kmeans = KMeans(n_clusters=3, random_state=42)
    dominant_colors = kmeans.fit(colors_flat).cluster_centers_
    
    # åˆ†æäº®åº¦
    brightness = np.mean(valid_pixels)
    
    # æ„å»ºadaptive prompt
    if brightness > 150:
        lighting = "bright daylight"
    elif brightness > 100:
        lighting = "natural lighting"
    else:
        lighting = "low light conditions"
    
    base_prompt = "complete urban street scene"
    detail_prompt = f"with {lighting}, maintaining consistent style and colors"
    
    return f"{base_prompt} {detail_prompt}"
```

---

## 10. ç»“è®º

### âœ… ç³»ç»ŸçŠ¶æ€æ€»ç»“

**å¢é‡å¼RGBDè¡¥å…¨ç³»ç»ŸåŸºæœ¬åŠŸèƒ½æ­£å¸¸ï¼Œé—®é¢˜å®šä½æ˜ç¡®ï¼š**

#### æ­£å¸¸å·¥ä½œçš„ç»„ä»¶
- âœ… ç¯å¢ƒåˆ‡æ¢ï¼šHunyuanWorld â†” flux-inpaintingç¨³å®š
- âœ… ç‚¹äº‘å¢é•¿ï¼š1.23%å¢é•¿ç‡ï¼Œå¢é‡æœºåˆ¶æœ‰æ•ˆ  
- âœ… FLUXè¡¥å…¨ï¼šRGB inpaintingè´¨é‡è‰¯å¥½
- âœ… ç›¸æœºè½¨è¿¹ï¼š72å¸§é¢„æ„å»ºè½¨è¿¹æ­£ç¡®
- âœ… Maskå¤„ç†ï¼šå·²å¯¹é½é˜ˆå€¼å’Œè†¨èƒ€å¤„ç†

#### æ ¸å¿ƒé—®é¢˜å·²å®šä½ 
- ğŸ¯ **æ·±åº¦ä¼°è®¡Scaleé”™è¯¯**ï¼šæ–°å¢ç‚¹åªæœ‰åŸå§‹scaleçš„7%
- ğŸ”§ **è§£å†³æ–¹æ¡ˆæ˜ç¡®**ï¼šå®ç°scale_awareæ·±åº¦ä¼°è®¡+è‡ªåŠ¨ä¿®æ­£

### ğŸš€ ä¸‹ä¸€æ­¥è¡ŒåŠ¨
1. **ç«‹å³ä¼˜å…ˆ**ï¼šé›†æˆ`fix_depth_estimation.py`åˆ°`incremental_pipeline.py`
2. **éªŒè¯æ•ˆæœ**ï¼šè¿è¡Œä¿®å¤åçš„pipelineç¡®è®¤scaleé—®é¢˜è§£å†³
3. **è´¨é‡ç›‘æ§**ï¼šæ·»åŠ å®æ—¶scaleæ£€æŸ¥å’Œä¿®æ­£æœºåˆ¶

**ç»“è®º**ï¼šç³»ç»Ÿæ¶æ„å®Œæ•´ï¼Œé—®é¢˜å®šä½ç²¾å‡†ï¼Œä¿®å¤æ–¹æ¡ˆå¯è¡Œã€‚æ·±åº¦ä¼°è®¡Scaleä¿®æ­£åï¼Œå¢é‡å¼3Dè¡¥å…¨å°†è¾¾åˆ°é¢„æœŸæ•ˆæœã€‚